{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-by-step demonstration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lib Imports and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "# %matplotlib inline \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ruptures as rpt\n",
    "from ruptures.metrics import precision_recall, meantime\n",
    "import scipy.stats as ss\n",
    "from itertools import islice\n",
    "\n",
    "sys.path.append(\"Codes/\")\n",
    "import TMPD_utils\n",
    "import TMPD_class\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_colwidth', 150)\n",
    "# pd.set_option('display.float_format', lambda x: f'{x:,.3f}')\n",
    "pd.options.display.float_format = '{:.4f}'.format\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading event log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping all event_logs paths\n",
    "logs_path = glob.glob(\"Input/Synthetic/Business Process Drift (Maaradji - Fast)/logs/*/*k.mxml\")\n",
    "\n",
    "# Removing the logs with 2500 and 5000 events (based on Maaradji paper)\n",
    "# logs_path = [x for x in logs_path if \"10\" in x or \"7.5\" in x]\n",
    "change_patterns_excluded = ['IOR', 'IRO', 'OIR', 'ORI', 'RIO', 'ROI', 'cp']\n",
    "logs_path = [x for x in logs_path if \"10\" in x and not any(keyword in x for keyword in change_patterns_excluded)] \n",
    "\n",
    "# Showing mapped paths\n",
    "print(\"How many logs? \", len(logs_path))\n",
    "pd.DataFrame(logs_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![Alt text](../Images/Concept_drift_firstcycle_steps_eng.png \"General steps\") -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading first event log\n",
    "log_path = logs_path[5]\n",
    "print(log_path.split(\"\\\\\")[-1].split(\".\")[0])\n",
    "event_log = TMPD_utils.parse_mxml(log_path)\n",
    "\n",
    "# This is a specifc step for this event log that separates in different rows the start and end of an activity. As we will only use one timestamp, we are filtering only the row representing the end of an activity.  \n",
    "event_log = event_log[event_log.EventType == \"complete\"]\n",
    "\n",
    "# Save original event index\n",
    "event_log = event_log.reset_index(names='original_index') \n",
    "\n",
    "# Create an id based on the order of the event in the raw event log\n",
    "event_log[\"Event_order_id\"] = event_log.index\n",
    "\n",
    "# This is a specifc step for this event log, because it have duplicated case ids. So we create a new case id.\n",
    "event_log[\"Trace_order\"] = TMPD_utils.cumulative_counting(event_log[\"CaseId\"])\n",
    "\n",
    "# # Add a Start and End activities case it doesn't have\n",
    "# event_log = TMPD_utils.add_start_end_activities(event_log=event_log, case_id_col=\"Trace_order\", activity_col=\"Activity\", timestamp_col=\"Timestamp\")\n",
    "\n",
    "# Showing loaded event log\n",
    "print(\"Total events: \", len(event_log))\n",
    "print(\"Total cases: \", len(event_log.groupby('CaseId')))\n",
    "print(\"Total activities: \", len(event_log.groupby('Activity')))\n",
    "event_log.head(15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Instantiating class and setting event log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniatializing the TMPD_class\n",
    "TMPD_instance = TMPD_class.TMPD(scenario='offline')\n",
    "\n",
    "# Setting the transition log\n",
    "TMPD_instance.set_transition_log(event_log, case_id='Trace_order', activity_key='Activity', timestamp_key='Timestamp', timestamp_format=None, other_columns_keys=[])\n",
    "\n",
    "# Executing the transition log\n",
    "TMPD_instance.run_transition_log()\n",
    "\n",
    "# Showing the transition log created\n",
    "print(len(TMPD_instance.get_transition_log()))\n",
    "TMPD_instance.get_transition_log().head(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Setting Window Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the window strategy parameters\n",
    "TMPD_instance.set_windowing_strategy(window_size_mode = 'Fixed', window_size = 4000, window_ref_mode = 'Fixed', overlap = True, sliding_step = 200, continuous = True)\n",
    "\n",
    "# Executing the window strategy indexation\n",
    "TMPD_instance.run_windowing_strategy()\n",
    "\n",
    "# Showing the windows indexes\n",
    "dict(list(TMPD_instance.get_windowing_strategy().items()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Setting Process Representation (using Transition Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the Transition Matrix (TM) process representation\n",
    "TMPD_instance.set_process_representation(threshold_anomaly=0.005\n",
    "                                    , control_flow_features={'frequency', 'probability'}\n",
    "                                    , time_features={} #{'avg_time':'timestamp', 'time_std':'timestamp'}\n",
    "                                    , resource_features={}\n",
    "                                    , data_features={})\n",
    "\n",
    "# Executing the process_representation using all dataset just for an example\n",
    "TMPD_instance.run_process_representation(TMPD_instance.transition_log)\n",
    "\n",
    "# Showing the process representation created\n",
    "TMPD_instance.get_process_representation()#.head(15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Setting Change Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the change features\n",
    "change_features_strategy_dict = {\n",
    "    'delta_matrix_strategy': \n",
    "        {\n",
    "            'frequency_delta' : {'process_feature':'frequency', 'method':'aggregation', 'agg_function' : 'sum'}\n",
    "            , 'probability_delta' : {'process_feature':'probability', 'method':'aggregation', 'agg_function' : 'sum'}\n",
    "            # , 'causality_delta' : {'process_feature':'causality', 'method':'aggregation', 'agg_function' : 'sum'}\n",
    "            # , 'parallel_delta' : {'process_feature':'parallel', 'method':'aggregation', 'agg_function' : 'sum'}\n",
    "            , 'frequency_delta_percentage' : {'process_feature':'frequency', 'method':'percentage'}\n",
    "            , 'prob_freq_delta_weight' : {'process_feature':'probability', 'method':'aggregation_weight', 'agg_function' : 'sum', 'weight_feature' : 'frequency'}\n",
    "            # , 'avg_time_delta' : {'process_feature':'avg_time', 'method':'aggregation', 'agg_function' : 'sum'}\n",
    "            # , 'time_std_delta' : {'process_feature':'time_std', 'method':'aggregation', 'agg_function' : 'sum'}\n",
    "        }\n",
    "    , 'statistic_test_strategy' : \n",
    "        {\n",
    "            'frequency_gtest_pvalue' : {'process_feature':'frequency', 'method':'g_test', 'contingency_matrix_sum_value' : '5', 'remove_zeros':'True'}\n",
    "            , 'frequency_cramersv' : {'process_feature':'frequency', 'method':'cramers_v', 'contingency_matrix_sum_value' : '5', 'remove_zeros':'True'}\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Setting Change Representation\n",
    "TMPD_instance.set_change_representation(change_features_strategy_dict)\n",
    "\n",
    "# Executing the Change Representation using the window strategy\n",
    "TMPD_instance.run_change_representation()\n",
    "\n",
    "# Showing the Change Representation created\n",
    "TMPD_instance.get_change_representation().head(15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Setting Detection Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining detection strategies\n",
    "detection_task_strategy_dict = {\n",
    "    'time_series_strategy': \n",
    "    {\n",
    "        'cpd_frequency_delta' : {'change_features':['frequency_delta'], 'method':'cpd_pelt', 'smooth' : '3'} #, 'model' : 'rbf', 'cost' : 'rpt.costs.CostRbf()', 'min_size' : '1', 'jump' : '1'\n",
    "        , 'cpd_prob_freq_delta' : {'change_features':['prob_freq_delta_weight'], 'method':'cpd_pelt', 'smooth' : '3'} #, 'model' : 'rbf', 'cost' : 'rpt.costs.CostRbf()', 'min_size' : '1', 'jump' : '1'\n",
    "        # , 'cpd_prob_causality_delta' : {'change_features':['causality_delta'], 'method':'cpd_pelt', 'smooth' : '3'} #, 'model' : 'rbf', 'cost' : 'rpt.costs.CostRbf()', 'min_size' : '1', 'jump' : '1'\n",
    "        # , 'cpd_prob_parallel_delta' : {'change_features':['parallel_delta'], 'method':'cpd_pelt', 'smooth' : '3'} #, 'model' : 'rbf', 'cost' : 'rpt.costs.CostRbf()', 'min_size' : '1', 'jump' : '1'\n",
    "        # , 'cpd_avg_time_delta' : {'change_features':['avg_time_delta'], 'method':'cpd_pelt', 'smooth' : '3'} #, 'model' : 'rbf', 'cost' : 'rpt.costs.CostRbf()', 'min_size' : '1', 'jump' : '1'\n",
    "        # , 'cpd_time_std_delta' : {'change_features':['time_std_delta'], 'method':'cpd_pelt', 'smooth' : '3'} #, 'model' : 'rbf', 'cost' : 'rpt.costs.CostRbf()', 'min_size' : '1', 'jump' : '1'\n",
    "        , 'cramersv_frequency' : {'change_features':['frequency_cramersv'], 'method':'cpd_pelt', 'smooth' : '3'} #, 'model' : 'rbf', 'cost' : 'rpt.costs.CostRbf()', 'min_size' : '1', 'jump' : '1'\n",
    "    }\n",
    "    , 'threshold_strategy' : \n",
    "    {\n",
    "        'gtest_frequency' : {'change_features':['frequency_gtest_pvalue'], 'method':'comparison_operator', 'operator' : 'le', 'threshold_value' : '0.025', 'smooth' : '3'}\n",
    "        , 'cramersv_frequency' : {'change_features':['frequency_cramersv'], 'method':'comparison_operator', 'operator' : 'ge', 'threshold_value' : '0.05', 'smooth' : '3'}\n",
    "        # , 'fixed_frequency_delta_percentage' : {'change_features':['frequency_delta_percentage'], 'method':'comparison_operator', 'operator' : 'ge', 'threshold_value' : '0.05', 'smooth' : '3'}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Setting Detection Task\n",
    "TMPD_instance.set_detection_task(detection_task_strategy_dict)\n",
    "\n",
    "# Executing the Detection Task\n",
    "TMPD_instance.run_detection_task()\n",
    "\n",
    "# Showing Detection Task Results\n",
    "TMPD_instance.get_detection_task()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Grounding truth\n",
    "log_size = event_log['Trace_order'].nunique()\n",
    "ground_truth_traces_indexes = list(range(int(log_size/10), log_size, int(log_size/10)))\n",
    "\n",
    "transition_log = TMPD_instance.get_transition_log()\n",
    "ground_truth_events_indexes = transition_log[transition_log['case_id'].isin(ground_truth_traces_indexes)].groupby('case_id').first()['transition_id'].to_list()\n",
    "\n",
    "# signals_indexes = signals.reset_index()\n",
    "signals = TMPD_instance.get_change_representation()\n",
    "ground_truth = []\n",
    "for ground_truth_events_index in ground_truth_events_indexes:\n",
    "    ground_truth.extend(signals[(signals['start'] <= ground_truth_events_index) \n",
    "                & (signals['end'] >= ground_truth_events_index)].head(1).index.to_list())\n",
    "ground_truth = ground_truth + [len(signals)]\n",
    "print(\"ground_truth: \", ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Validation metrics\n",
    "margin_error_defined=3\n",
    "detection_task_results = TMPD_instance.get_detection_task()\n",
    "for index, row in detection_task_results.iterrows():\n",
    "    try:\n",
    "        detection_task_results.loc[index, 'ground_truth'] = str(ground_truth)\n",
    "\n",
    "        # smooth = int(detection_task_strategy_dict[row['detection_strategy']][row['detection_feature']]['smooth'])\n",
    "\n",
    "        # Margin of error give more margin to overlap if used.\n",
    "        margin_error = int(margin_error_defined + 1)  if TMPD_instance.overlap == False else int(margin_error_defined + 1 + TMPD_instance.window_size/TMPD_instance.sliding_step)\n",
    "\n",
    "        precision, recall = precision_recall(ground_truth, row['detection_results'], margin=margin_error)\n",
    "\n",
    "        f1 = round(ss.hmean([precision, recall]),2)\n",
    "        detection_task_results.loc[index, 'f1'] = f1\n",
    "        \n",
    "        delay = round(meantime(ground_truth, row['detection_results']), 2)\n",
    "        detection_task_results.loc[index, 'delay'] = delay\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        detection_task_results.loc[index, 'ground_truth'] = str(ground_truth)\n",
    "        detection_task_results.loc[index, 'f1'] = np.nan\n",
    "        detection_task_results.loc[index, 'delay'] = np.nan\n",
    "    \n",
    "detection_task_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Display Detection Task Results \n",
    "\n",
    "for result in detection_task_results.itertuples():\n",
    "    fig, axarr = rpt.display(signal = TMPD_instance.get_change_representation()[TMPD_instance.detection_task_strategy_dict[result.detection_strategy][result.detection_feature]['change_features']]\n",
    "                , true_chg_pts=ground_truth\n",
    "                , computed_chg_pts = result.detection_results\n",
    "                , computed_chg_pts_color = \"k\"\n",
    "                , computed_chg_pts_linewidth = 4\n",
    "                , computed_chg_pts_linestyle = \"--\"\n",
    "                , computed_chg_pts_alpha = 1\n",
    "                , figsize=(15, 2)\n",
    "                )\n",
    "    plt.suptitle(\"Change pattern: \" + log_path.split(\"\\\\\")[-2] \n",
    "                 + \" - Log size: \" + str(log_size)\n",
    "                 + \" - Feature: \" + result.detection_feature\n",
    "                 + \" - F1: \" + str(result.f1) \n",
    "                 + \" - Delay: \" + str(result.delay)\n",
    "                 , fontsize=20)\n",
    "    plt.subplots_adjust(top=0.8)\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6a - Setting Localization Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Localization Task\n",
    "TMPD_instance.set_localization_task(reference_window_index=0, detection_window_index=75, pvalue_threshold=0.05, effect_prop_threshold=0.2, effect_count_threshold=0.02, pseudo_count=5)\n",
    "\n",
    "# Executing Localization Task\n",
    "TMPD_instance.run_localization_task()\n",
    "\n",
    "# Showing Localization Task Results\n",
    "TMPD_instance.get_localization_task(show_localization_dfg=True, show_original_dfg=False, show_original_bpmn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ground Truth\n",
    "change_pattern_ground_truth = log_path.split(\"\\\\\")[-2]\n",
    "\n",
    "change_activities_ground_truth = {\n",
    "    'cb': {\n",
    "        'change_pattern_name': 'Skip',\n",
    "        'characterization_activities': ['Check_if_home_insurance_quote_is_requested', 'Prepare_acceptance_pack'],\n",
    "        'localization_activities': ['Send_acceptance_pack', 'Check_if_home_insurance_quote_is_requested', 'Prepare_acceptance_pack', 'Assess_eligibility', 'Send_home_insurance_quote']\n",
    "    },\n",
    "    'cd': {\n",
    "        'change_pattern_name': 'Control-Dependency',\n",
    "        'characterization_activities': ['Check_credit_history', 'Assess_loan_risk'],\n",
    "        'localization_activities': ['Assess_loan_risk', 'Appraise_property', 'Assess_eligibility', 'Check_credit_history']\n",
    "    },\n",
    "    'cf': {\n",
    "        'change_pattern_name': 'Conditional-To-Sequence',\n",
    "        'characterization_activities': ['Send_home_insurance_quote', 'Send_acceptance_pack'],\n",
    "        'localization_activities': ['Check_if_home_insurance_quote_is_requested', 'Send_home_insurance_quote', 'Send_acceptance_pack', 'Verify_repayment_agreement']\n",
    "    },\n",
    "    'cm': {\n",
    "        'change_pattern_name': 'Conditional-Move',\n",
    "        'characterization_activities': ['Prepare_acceptance_pack'],\n",
    "        'localization_activities': ['Send_acceptance_pack', 'Check_if_home_insurance_quote_is_requested', 'Prepare_acceptance_pack', 'Assess_eligibility', 'Send_home_insurance_quote', 'Verify_repayment_agreement']\n",
    "    },\n",
    "    'cp': {\n",
    "        'change_pattern_name': 'Copy',\n",
    "        'characterization_activities': ['Assess_loan_risk', 'Check_credit_history'],\n",
    "        'localization_activities': ['Assess_loan_risk', 'Check_credit_history', 'Verify_repayment_agreement', 'Approve_application', 'Cancel_application']\n",
    "    },\n",
    "    'fr': {\n",
    "        'change_pattern_name': 'Frequency',\n",
    "        'characterization_activities': ['Check_if_home_insurance_quote_is_requested', 'Send_home_insurance_quote', 'Send_acceptance_pack', 'Verify_repayment_agreement'],\n",
    "        'localization_activities': ['Check_if_home_insurance_quote_is_requested', 'Send_home_insurance_quote', 'Send_acceptance_pack', 'Verify_repayment_agreement']\n",
    "    },\n",
    "    'lp': {\n",
    "        'change_pattern_name': 'Loop',\n",
    "        'characterization_activities': ['Assess_loan_risk', 'Appraise_property', 'Assess_eligibility', 'Check_credit_history'],\n",
    "        'localization_activities': ['Assess_loan_risk', 'Appraise_property', 'Assess_eligibility', 'Check_credit_history', 'Reject_application', 'Prepare_acceptance_pack']\n",
    "    },\n",
    "    'pl': {\n",
    "        'change_pattern_name': 'Parallel-To-Sequence',\n",
    "        'characterization_activities': ['Appraise_property', 'Check_credit_history', 'Assess_loan_risk'],\n",
    "        'localization_activities': ['Assess_loan_risk', 'Check__application__form_completeness', 'Appraise_property', 'Assess_eligibility', 'Check_credit_history']\n",
    "    },\n",
    "    'pm': {\n",
    "        'change_pattern_name': 'Parallel-Move',\n",
    "        'characterization_activities': ['Prepare_acceptance_pack', 'Send_home_insurance_quote'],\n",
    "        'localization_activities': ['Send_acceptance_pack', 'Check_if_home_insurance_quote_is_requested', 'Prepare_acceptance_pack', 'Assess_eligibility', 'Send_home_insurance_quote', 'Verify_repayment_agreement']\n",
    "    },\n",
    "    're': {\n",
    "        'change_pattern_name': 'Serial-Switch',\n",
    "        'characterization_activities': ['Assess_eligibility'],\n",
    "        'localization_activities': ['Assess_eligibility', 'Reject_application', 'Prepare_acceptance_pack', 'Assess_loan_risk']\n",
    "    },\n",
    "    'rp': {\n",
    "        'change_pattern_name': 'Replace',\n",
    "        'characterization_activities': ['Verify_repayment_agreement', 'Replaced_Activity'],\n",
    "        'localization_activities': ['Cancel_application', 'Send_acceptance_pack', 'Replaced_Activity', 'Approve_application', 'Send_home_insurance_quote', 'Verify_repayment_agreement']\n",
    "    },\n",
    "    'sw': {\n",
    "        'change_pattern_name': 'Swap',\n",
    "        'characterization_activities': ['Prepare_acceptance_pack', 'Check_if_home_insurance_quote_is_requested', 'Verify_repayment_agreement'],\n",
    "        'localization_activities': ['Send_acceptance_pack', 'Cancel_application', 'Check_if_home_insurance_quote_is_requested', 'Approve_application', 'Prepare_acceptance_pack', 'Assess_eligibility', 'Send_home_insurance_quote', 'Verify_repayment_agreement']\n",
    "    }\n",
    "    # , 'IOR': []\n",
    "    # , 'IRO': []\n",
    "    # , 'OIR': []\n",
    "    # , 'ORI': []\n",
    "    # , 'RIO': []\n",
    "    # , 'ROI': []\n",
    "}\n",
    "\n",
    "localization_ground_truth = change_activities_ground_truth[change_pattern_ground_truth]['localization_activities']\n",
    "localization_ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Validation metrics\n",
    "\n",
    "# Getting the distinct activities in the Localization Result\n",
    "localization_distinct_activities = set()\n",
    "for key, value in islice(TMPD_instance.get_localization_task(show_localization_dfg=False, show_original_dfg=False, show_original_bpmn=False)[1].items(), 6):\n",
    "    if isinstance(value, list): # Check if the value is a list\n",
    "        # Skip the list if it contains only \"None\"\n",
    "        if len(value) == 1 and value[0] == \"None\":\n",
    "            continue\n",
    "        for item in value:\n",
    "            if isinstance(item, tuple): # If the items are tuples, extend the set with the tuple items\n",
    "                localization_distinct_activities.update(item)\n",
    "            else: # If the items are not tuples (i.e., strings), add them directly to the set\n",
    "                localization_distinct_activities.add(item)\n",
    "localization_result = list(localization_distinct_activities)\n",
    "print(localization_result)\n",
    "\n",
    "# Set comparison for 'Activities'\n",
    "precision, recall, f1_score = TMPD_utils.list_match_metrics(localization_ground_truth, localization_result)\n",
    "\n",
    "localization_task_validation_results = ({\n",
    "    'localization_activities_precision': precision,\n",
    "    'localization_activities_recall': recall,\n",
    "    'localization_activities_f1_score': f1_score\n",
    "})\n",
    "\n",
    "localization_task_validation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Skip Pattern temporary test\n",
    "# TMPD_instance.detection_bpmn_text = \"Sequence( 'Loan__application_received', Loop( 'Check__application__form_completeness', Sequence( 'Return_application_back_to_applicant', 'Receive_updated_application' ) ), Parallel( 'Appraise_property', Sequence( 'Check_credit_history', 'Assess_loan_risk' ) ), 'Assess_eligibility', Conditional( Sequence( Conditional( Sequence( 'Prepare_acceptance_pack', 'Check_if_home_insurance_quote_is_requested') , 'tau'), Conditional( 'Send_acceptance_pack', 'Send_home_insurance_quote' ), 'Verify_repayment_agreement', Conditional( Sequence( 'Cancel_application', 'Loan__application_canceled' ), Sequence( 'Approve_application', 'Loan__application_approved' ) ) ), Sequence( 'Reject_application', 'Loan_application_rejected' ) ) )\"\n",
    "# TMPD_instance.detection_bpmn_text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6b - Setting Characterization Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Characterization Task\n",
    "TMPD_instance.set_characterization_task(llm_company = \"openai\", llm_model=\"gpt-4o\", api_key_path='Temp/openai_api_key.txt', llm_instructions_path='Codes/LLM_Instructions/instructions_v0.yaml') # \"gpt-4o\", \"gpt-3.5-turbo-0125\", \"gpt-4\"\n",
    "\n",
    "# Executing Characterization Task\n",
    "TMPD_instance.run_characterization_task()\n",
    "\n",
    "# Showing Characterization Task Results\n",
    "TMPD_instance.get_characterization_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ground Truth\n",
    "\n",
    "characterization_ground_truth = {'concept_drift' : ['Yes'], 'change_pattern' : [change_activities_ground_truth[change_pattern_ground_truth]['change_pattern_name']], 'activities' : change_activities_ground_truth[change_pattern_ground_truth]['characterization_activities']}\n",
    "characterization_ground_truth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Validation metrics\n",
    "\n",
    "characterization_result = TMPD_instance.get_characterization_task()[0]\n",
    "\n",
    "# Initialize a results dictionary\n",
    "characterization_task_validation_results = {\n",
    "    'characterization_concept_drift_match': None,\n",
    "    'characterization_change_pattern_match_f1_score': None,\n",
    "    'characterization_change_pattern_match_precision': None,\n",
    "    'characterization_change_pattern_match_recall': None,\n",
    "    'characterization_activities_precision': None,\n",
    "    'characterization_activities_recall': None,\n",
    "    'characterization_activities_f1_score': None\n",
    "}\n",
    "\n",
    "# Check matches\n",
    "try:\n",
    "    characterization_task_validation_results['characterization_concept_drift_match'] = TMPD_utils.list_match_metrics(characterization_ground_truth['concept_drift'], characterization_result['concept_drift'])[2]\n",
    "except:\n",
    "    characterization_task_validation_results['characterization_concept_drift_match'] = -1\n",
    "\n",
    "try:\n",
    "    precision, recall, f1_score = TMPD_utils.list_match_metrics(characterization_ground_truth['change_pattern'], characterization_result['change_pattern'])\n",
    "    characterization_task_validation_results.update({\n",
    "        'characterization_change_pattern_match_f1_score': f1_score,\n",
    "        'characterization_change_pattern_match_precision': precision,\n",
    "        'characterization_change_pattern_match_recall': recall\n",
    "    })\n",
    "\n",
    "except:\n",
    "    characterization_task_validation_results.update({\n",
    "        'characterization_change_pattern_match_f1_score': -1,\n",
    "        'characterization_change_pattern_match_precision': -1,\n",
    "        'characterization_change_pattern_match_recall': -1\n",
    "    })\n",
    "\n",
    "# Set comparison for 'Activities'\n",
    "precision, recall, f1_score = TMPD_utils.list_match_metrics(characterization_ground_truth['activities'], characterization_result['activities'])\n",
    "\n",
    "characterization_task_validation_results.update({\n",
    "    'characterization_activities_precision': precision,\n",
    "    'characterization_activities_recall': recall,\n",
    "    'characterization_activities_f1_score': f1_score\n",
    "})\n",
    "\n",
    "characterization_task_validation_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "understanding_tasks_results = pd.DataFrame([{**characterization_task_validation_results}])\n",
    "understanding_tasks_results['localization_activities'] = ', '.join(localization_result) \n",
    "understanding_tasks_results['characterization_change_pattern'] = ', '.join(TMPD_instance.get_characterization_task()[0]['change_pattern']) \n",
    "understanding_tasks_results['characterization_activities'] = ', '.join(TMPD_instance.get_characterization_task()[0]['activities']) \n",
    "understanding_tasks_results['localization_changes'] = [TMPD_instance.get_localization_task(show_localization_dfg=False, show_original_dfg=False, show_original_bpmn=False)[1]]\n",
    "understanding_tasks_results['reference_bpmn_text'] = TMPD_instance.get_localization_task(show_localization_dfg=False, show_original_dfg=False, show_original_bpmn=False)[2]\n",
    "understanding_tasks_results['detection_bpmn_text'] = TMPD_instance.get_localization_task(show_localization_dfg=False, show_original_dfg=False, show_original_bpmn=False)[3]\n",
    "understanding_tasks_results['change_patterns_llm_response'] = TMPD_instance.get_characterization_task()[1]\n",
    "understanding_tasks_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4479e0a5046c62b3193360939b9555042324f3c1ca8424e4ac0e4f7948559ebe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
