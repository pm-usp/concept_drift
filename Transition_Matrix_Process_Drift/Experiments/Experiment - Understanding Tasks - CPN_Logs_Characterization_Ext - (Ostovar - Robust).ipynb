{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: Understanding Tasks (Localization, Characterization, and Explanation) on CPN_Logs_Characterization_Ext - (Ostovar - Robust)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lib Imports and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib notebook\n",
    "# %matplotlib inline \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import io\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pm4py\n",
    "import ruptures as rpt\n",
    "from ruptures.metrics import precision_recall, meantime\n",
    "import scipy.stats as ss\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import time\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "sys.path.append(\"../Codes/\")\n",
    "import TMPD_utils\n",
    "import TMPD_class\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_colwidth', 150)\n",
    "# pd.set_option('display.float_format', lambda x: f'{x:,.3f}')\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "np.set_printoptions(threshold=sys.maxsize)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to run the class TMPD pipeline in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline_TMPD(kwargs, display=False, return_bool=False):\n",
    "\n",
    "    try:\n",
    "        print(kwargs['log_path'])\n",
    "        ### Loading event log\n",
    "        # Extracting event log\n",
    "        event_log = TMPD_utils.parse_mxml(kwargs['log_path'], gzip=True)\n",
    "\n",
    "        # This is a specifc step for this event log that remove an activity that shows where the drift happens\n",
    "        event_log = event_log[event_log['WorkflowModelElement'] != 'DRIFT_PO']\n",
    "\n",
    "        # Save original event index\n",
    "        event_log = event_log.reset_index(names='original_index') \n",
    "\n",
    "        # Create an id based on the order of the event in the raw event log\n",
    "        event_log[\"Event_order_id\"] = event_log.index\n",
    "\n",
    "\n",
    "        ### Step 1 - Instantiating class and setting event log\n",
    "        print('step 1')\n",
    "        # Iniatializing the TMPD_class\n",
    "        TMPD_instance = TMPD_class.TMPD(scenario='offline')\n",
    "\n",
    "        # Setting the transition log\n",
    "        TMPD_instance.set_transition_log(event_log, case_id = kwargs['case_id'], activity_key = kwargs['activity_key']\n",
    "                                         , timestamp_key = kwargs['timestamp_key'], timestamp_format=kwargs['timestamp_format'], other_columns_keys=kwargs['other_columns_keys'])\n",
    "\n",
    "        # Executing the transition log\n",
    "        TMPD_instance.run_transition_log()\n",
    "\n",
    "        # Showing the transition log created\n",
    "        # TMPD_instance.get_transition_log().head(15)\n",
    "\n",
    "        \n",
    "        ### Step 2 - Window Strategy\n",
    "        print('step 2')\n",
    "        # Setting the window strategy parameters\n",
    "        TMPD_instance.set_windowing_strategy(window_size_mode = kwargs['window_size_mode'], window_size = kwargs['window_size'], window_ref_mode = kwargs['window_ref_mode']\n",
    "                                                , overlap = kwargs['overlap'], sliding_step = kwargs['sliding_step'])\n",
    "\n",
    "        # Executing the window strategy indexation\n",
    "        TMPD_instance.run_windowing_strategy()\n",
    "\n",
    "        # Showing the windows indexes\n",
    "        # dict(list(TMPD_instance.get_windowing_strategy().items())[:15])\n",
    "\n",
    "\n",
    "        ### Step 3 - Process Representation (using Transition Matrix)\n",
    "        print('step 3')\n",
    "        # Setting the Transition Matrix (TM) process representation\n",
    "        TMPD_instance.set_process_representation(threshold_anomaly = kwargs['threshold_anomaly']\n",
    "                                            , control_flow_features = kwargs['control_flow_features']\n",
    "                                            , time_features = kwargs['time_features']\n",
    "                                            , resource_features = kwargs['resource_features']\n",
    "                                            , data_features = kwargs['data_features'])\n",
    "\n",
    "        # Executing the process_representation using all dataset just for an example\n",
    "        # TMPD_instance.run_process_representation(TMPD_instance.transition_log)\n",
    "\n",
    "        # Showing the process representation created\n",
    "        # TMPD_instance.get_process_representation().head(15)\n",
    "\n",
    "\n",
    "        ### Step 4 - Change Representation\n",
    "        print('step 4')\n",
    "        # Setting Change Representation\n",
    "        TMPD_instance.set_change_representation(kwargs['change_features_strategy_dict'])\n",
    "\n",
    "        # Executing the Change Representation using the window strategy\n",
    "        TMPD_instance.run_change_representation()\n",
    "\n",
    "        # Showing the Change Representation created\n",
    "        # TMPD_instance.get_change_representation().head(15)\n",
    "\n",
    "\n",
    "        ### Step 5 - Detection Task\n",
    "        # print('step 5')\n",
    "        # # Setting Detection Task\n",
    "        # TMPD_instance.set_detection_task(kwargs['detection_task_strategy_dict'])\n",
    "\n",
    "        # # Executing the Detection Task\n",
    "        # TMPD_instance.run_detection_task()\n",
    "\n",
    "        # # Getting Detection Task Results\n",
    "        # detection_task_results = TMPD_instance.get_detection_task()\n",
    "\n",
    "\n",
    "        ### Step 6a - Localization Task\n",
    "        print('step 6a')\n",
    "        # Setting Localization Task\n",
    "        TMPD_instance.set_localization_task(reference_window_index=kwargs['reference_window_index'], detection_window_index=kwargs['detection_window_index']\n",
    "                                            , pvalue_threshold=kwargs['pvalue_threshold'], effect_threshold=kwargs['effect_threshold'], presence_percentage_threshold=kwargs['presence_percentage_threshold'], pseudo_count=kwargs['pseudo_count'])\n",
    "\n",
    "        # Executing Localization Task\n",
    "        TMPD_instance.run_localization_task()\n",
    "\n",
    "        # Showing Localization Task Results\n",
    "        significant_transition_changes, high_level_changes, reference_bpmn_text, detection_bpmn_text = TMPD_instance.get_localization_task(show_localization_dfg=False, show_original_dfg=False, show_original_bpmn=False)\n",
    "\n",
    "        # Getting the distinct activities in the Localization Result\n",
    "        localization_distinct_activities = set()\n",
    "        for key, value in high_level_changes.items():\n",
    "            if isinstance(value, list): # Check if the value is a list\n",
    "                # Skip the list if it contains only \"None\"\n",
    "                if len(value) == 1 and value[0] == \"None\":\n",
    "                    continue\n",
    "                for item in value:\n",
    "                    if isinstance(item, tuple): # If the items are tuples, extend the set with the tuple items\n",
    "                        localization_distinct_activities.update(item)\n",
    "                    else: # If the items are not tuples (i.e., strings), add them directly to the set\n",
    "                        localization_distinct_activities.add(item)\n",
    "        localization_result = list(localization_distinct_activities)\n",
    "\n",
    "\n",
    "        ### Step 6b - Characterization Task\n",
    "        print('step 6b')\n",
    "        # Setting Characterization Task\n",
    "        TMPD_instance.set_characterization_task(llm_company = kwargs['llm_company'], llm_model=kwargs['llm_model'], api_key_path=kwargs['api_key_path'], llm_instructions_path=kwargs['llm_instructions_path'])\n",
    "\n",
    "        # Executing Characterization Task\n",
    "        TMPD_instance.run_characterization_task()\n",
    "\n",
    "        # Getting Characterization Task\n",
    "        characterization_prompt, characterization_response = TMPD_instance.get_characterization_task()\n",
    "\n",
    "        ### Defining Grounding truth\n",
    "        change_pattern_ground_truth = kwargs['log_path'].split(\"\\\\\")[-3]\n",
    "\n",
    "        change_activities_ground_truth = {\n",
    "            'ConditionalMove': {\n",
    "                'change_pattern_name': 'Conditional-Move',\n",
    "                'characterization_activities': ['n', 'p'],\n",
    "                'localization_activities': ['n', 'p', 't', 'o', 'u']\n",
    "            },\n",
    "            'ConditionalRemoval': {\n",
    "                'change_pattern_name': 'Conditional-Removal',\n",
    "                'characterization_activities': ['re'],\n",
    "                'localization_activities': ['re', 'y', 'z']\n",
    "            },\n",
    "            'ConditionalToSequence': {\n",
    "                'change_pattern_name': 'Conditional-To-Sequence',\n",
    "                'characterization_activities': ['p', 'q'],\n",
    "                'localization_activities': ['p', 'q', 'u', 'o']\n",
    "            },\n",
    "            'Frequency': {\n",
    "                'change_pattern_name': 'Frequency',\n",
    "                'characterization_activities': ['p', 'q', 'o'],\n",
    "                'localization_activities': ['p', 'q', 'o']\n",
    "            },\n",
    "            'Loop': {\n",
    "                'change_pattern_name': 'Loop',\n",
    "                'characterization_activities': ['k'],\n",
    "                'localization_activities': ['k']\n",
    "            },\n",
    "            'ParallelMove': {\n",
    "                'change_pattern_name': 'Parallel-Move',\n",
    "                'characterization_activities': ['n', 'p'],\n",
    "                'localization_activities': ['n', 'p', 't', 'o', 'u']\n",
    "            },\n",
    "            'ParallelRemoval': {\n",
    "                'change_pattern_name': 'Parallel-Removal',\n",
    "                'characterization_activities': ['re'],\n",
    "                'localization_activities': ['y', 'z', 'z1']\n",
    "            },\n",
    "            'ParallelToSequence': {\n",
    "                'change_pattern_name': 'Parallel-To-Sequence',\n",
    "                'characterization_activities': ['n', 'o'],\n",
    "                'localization_activities': ['n', 'o', 't', 'p']\n",
    "            },\n",
    "            'SerialMove': {\n",
    "                'change_pattern_name': 'Serial-Move',\n",
    "                'characterization_activities': ['n'],\n",
    "                'localization_activities': ['n', 'p', 't', 'o', 'u']\n",
    "            },\n",
    "            'SerialRemoval': {\n",
    "                'change_pattern_name': 'Serial-Removal',\n",
    "                'characterization_activities': ['re'],\n",
    "                'localization_activities': ['re', 'y', 'z']\n",
    "            },\n",
    "            'Skip': {\n",
    "                'change_pattern_name': 'Skip',\n",
    "                'characterization_activities': ['n'],\n",
    "                'localization_activities': ['n', 't', 'o']\n",
    "            },\n",
    "            'Substitute': {\n",
    "                'change_pattern_name': 'Replace',\n",
    "                'characterization_activities': ['sub', 'z1'],\n",
    "                'localization_activities': ['sub', 'z1', 'z', 'y']\n",
    "            },\n",
    "            'Swap': {\n",
    "                'change_pattern_name': 'Swap',\n",
    "                'characterization_activities': ['n', 'o'],\n",
    "                'localization_activities': ['n', 'o', 't', 'p', 'u']\n",
    "            } \n",
    "        }\n",
    "\n",
    "        localization_ground_truth = change_activities_ground_truth[change_pattern_ground_truth]['localization_activities']\n",
    "\n",
    "        ### Validation metrics\n",
    "        print('Validation metrics')\n",
    "\n",
    "        ## Localization\n",
    "        # Set comparison for 'Activities'\n",
    "        precision, recall, f1_score = TMPD_utils.list_match_metrics(localization_ground_truth, localization_result)\n",
    "\n",
    "        localization_task_validation_results = ({\n",
    "            'localization_activities_precision': precision,\n",
    "            'localization_activities_recall': recall,\n",
    "            'localization_activities_f1_score': f1_score\n",
    "        })\n",
    "\n",
    "        ## Characterization - Manual\n",
    "\n",
    "        understanding_tasks_results = pd.DataFrame()\n",
    "\n",
    "        understanding_tasks_results['localization_activities'] = [', '.join(localization_result)]\n",
    "        understanding_tasks_results['localization_ground_truth'] = [', '.join(localization_ground_truth)]\n",
    "        understanding_tasks_results['localization_activities_precision'] = [localization_task_validation_results['localization_activities_precision']]\n",
    "        understanding_tasks_results['localization_activities_recall'] = [localization_task_validation_results['localization_activities_recall']]\n",
    "        understanding_tasks_results['localization_activities_f1_score'] = [localization_task_validation_results['localization_activities_f1_score']]\n",
    "        understanding_tasks_results['reference_bpmn_text'] = [reference_bpmn_text]\n",
    "        understanding_tasks_results['detection_bpmn_text'] = [detection_bpmn_text]\n",
    "        understanding_tasks_results['characterization_prompt'] = [characterization_prompt]\n",
    "        understanding_tasks_results['characterization_response'] = [characterization_response]\n",
    "        # understanding_tasks_results['characterization_llm_response'] = [llm_respose_patterns]\n",
    "        understanding_tasks_results['characterization_ground_truth'] = [change_activities_ground_truth[change_pattern_ground_truth]['change_pattern_name']]\n",
    "        # understanding_tasks_results['characterization_change_pattern_match_f1_score'] = [characterization_task_validation_results['characterization_change_pattern_match_f1_score']]\n",
    "        # understanding_tasks_results['characterization_change_pattern_match_precision'] = [characterization_task_validation_results['characterization_change_pattern_match_precision']]\n",
    "        # understanding_tasks_results['characterization_change_pattern_match_recall'] = [characterization_task_validation_results['characterization_change_pattern_match_recall']]\n",
    "        \n",
    "\n",
    "        ### Add informations to final result\n",
    "        print('Adding informations')\n",
    "        understanding_tasks_results['log_path'] = kwargs['log_path']\n",
    "        understanding_tasks_results['log_size'] = kwargs['log_path'].split(\"\\\\\")[-5] \n",
    "        understanding_tasks_results['mix_type'] = kwargs['log_path'].split(\"\\\\\")[-4]\n",
    "        understanding_tasks_results['change_pattern'] = kwargs['log_path'].split(\"\\\\\")[-3]\n",
    "        understanding_tasks_results['noise_size'] = kwargs['log_path'].split(\"\\\\\")[-1].split(\".\")[0].split(\"_\")[-1] if kwargs['log_path'].split(\"\\\\\")[-1].split(\".\")[0].split(\"_\")[-1].isdigit() else 0\n",
    "        understanding_tasks_results['window_size_mode'] = kwargs['window_size_mode']\n",
    "        understanding_tasks_results['window_size'] = kwargs['window_size']\n",
    "        understanding_tasks_results['window_ref_mode'] = kwargs['window_ref_mode']\n",
    "        understanding_tasks_results['overlap'] = kwargs['overlap']\n",
    "        understanding_tasks_results['sliding_step'] = kwargs['sliding_step']\n",
    "\n",
    "        understanding_tasks_results['reference_window_index'] = kwargs['reference_window_index']\n",
    "        understanding_tasks_results['detection_window_index'] = kwargs['detection_window_index']\n",
    "        understanding_tasks_results['pvalue_threshold'] = kwargs['pvalue_threshold']\n",
    "        understanding_tasks_results['effect_threshold'] = kwargs['effect_threshold']\n",
    "        understanding_tasks_results['presence_percentage_threshold'] = kwargs['presence_percentage_threshold']\n",
    "        understanding_tasks_results['pseudo_count'] = kwargs['pseudo_count']\n",
    "        understanding_tasks_results['llm_company'] = kwargs['llm_company']\n",
    "        understanding_tasks_results['llm_model'] = kwargs['llm_model']\n",
    "        understanding_tasks_results['llm_instructions_path'] = kwargs['llm_instructions_path']\n",
    "\n",
    "    \n",
    "\n",
    "    except Exception as e:\n",
    "        understanding_tasks_results = pd.DataFrame(data={'Error': [e]})\n",
    "        understanding_tasks_results['log_path'] = kwargs['log_path']\n",
    "        understanding_tasks_results['log_size'] = kwargs['log_path'].split(\"\\\\\")[-5] \n",
    "        understanding_tasks_results['mix_type'] = kwargs['log_path'].split(\"\\\\\")[-4]\n",
    "        understanding_tasks_results['change_pattern'] = kwargs['log_path'].split(\"\\\\\")[-3]\n",
    "        understanding_tasks_results['noise_size'] = kwargs['log_path'].split(\"\\\\\")[-1].split(\".\")[0].split(\"_\")[-1] if kwargs['log_path'].split(\"\\\\\")[-1].split(\".\")[0].split(\"_\")[-1].isdigit() else 0\n",
    "        understanding_tasks_results['window_size_mode'] = kwargs['window_size_mode']\n",
    "        understanding_tasks_results['window_size'] = kwargs['window_size']\n",
    "        understanding_tasks_results['window_ref_mode'] = kwargs['window_ref_mode']\n",
    "        understanding_tasks_results['overlap'] = kwargs['overlap']\n",
    "        understanding_tasks_results['sliding_step'] = kwargs['sliding_step']\n",
    "\n",
    "        understanding_tasks_results['reference_window_index'] = kwargs['reference_window_index']\n",
    "        understanding_tasks_results['detection_window_index'] = kwargs['detection_window_index']\n",
    "        understanding_tasks_results['pvalue_threshold'] = kwargs['pvalue_threshold']\n",
    "        understanding_tasks_results['effect_threshold'] = kwargs['effect_threshold']\n",
    "        understanding_tasks_results['presence_percentage_threshold'] = kwargs['presence_percentage_threshold']\n",
    "        understanding_tasks_results['pseudo_count'] = kwargs['pseudo_count']\n",
    "        understanding_tasks_results['llm_company'] = kwargs['llm_company']\n",
    "        understanding_tasks_results['llm_model'] = kwargs['llm_model']\n",
    "        understanding_tasks_results['llm_instructions_path'] = kwargs['llm_instructions_path']\n",
    "    \n",
    "    # Deleting class instance\n",
    "    try:\n",
    "        del TMPD_instance\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Returning detection results or save to file\n",
    "    if return_bool:\n",
    "        return understanding_tasks_results\n",
    "    else:\n",
    "        understanding_tasks_results.to_pickle(\"Results/Understanding_CPN_Logs_Characterization_Ext_files/\"+ str(kwargs['id']) + \".pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading CPN_Logs_Characterization_Ext - (Ostovar - Robust) event logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many logs?  13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\ConditionalMove\\output\\ConditionalMove.mxml.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\ConditionalRemoval\\output\\ConditionalRemoval.mxml.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\ConditionalToSequence\\output\\ConditionalToSequence.mxml.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\Frequency\\output\\Frequency.mxml.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\Loop\\output\\Loop.mxml.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\ParallelMove\\output\\ParallelMove.mxml.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\ParallelRemoval\\output\\ParallelRemoval.mxml.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\ParallelToSequence\\output\\ParallelToSequence.mxml.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\SerialMove\\output\\SerialMove.mxml.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\SerialRemoval\\output\\SerialRemoval.mxml.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\Skip\\output\\Skip.mxml.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\Substitute\\output\\Substitute.mxml.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\Swap\\output\\Swap.mxml.gz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                        0\n",
       "0               ../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\ConditionalMove\\output\\ConditionalMove.mxml.gz\n",
       "1         ../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\ConditionalRemoval\\output\\ConditionalRemoval.mxml.gz\n",
       "2   ../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\ConditionalToSequence\\output\\ConditionalToSequence.mxml.gz\n",
       "3                           ../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\Frequency\\output\\Frequency.mxml.gz\n",
       "4                                     ../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\Loop\\output\\Loop.mxml.gz\n",
       "5                     ../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\ParallelMove\\output\\ParallelMove.mxml.gz\n",
       "6               ../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\ParallelRemoval\\output\\ParallelRemoval.mxml.gz\n",
       "7         ../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\ParallelToSequence\\output\\ParallelToSequence.mxml.gz\n",
       "8                         ../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\SerialMove\\output\\SerialMove.mxml.gz\n",
       "9                   ../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\SerialRemoval\\output\\SerialRemoval.mxml.gz\n",
       "10                                    ../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\Skip\\output\\Skip.mxml.gz\n",
       "11                        ../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\Substitute\\output\\Substitute.mxml.gz\n",
       "12                                    ../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\Swap\\output\\Swap.mxml.gz"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping all event_logs paths\n",
    "logs_path = glob.glob(\"../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange/*/*/*/*/*.mxml.gz\")\n",
    "\n",
    "# Temp filter\n",
    "logs_path = [x for x in logs_path if \"_2\" not in x and \"_5\" not in x and \"Size1\" in x and \"Atomic\" in x]\n",
    "\n",
    "# Showing mapped paths\n",
    "print(\"How many logs? \", len(logs_path))\n",
    "pd.DataFrame(logs_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![Alt text](../Images/Concept_drift_firstcycle_steps_eng.png \"General steps\") -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment impacts of the parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Parameters GridSearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMPD_ParameterGrid_experiment = ParameterGrid(\n",
    "    [{\n",
    "        # Step 1 - Instantiating class and setting event log\n",
    "        'case_id' : ['CaseId']\n",
    "        , 'activity_key' : ['Activity']\n",
    "        , 'timestamp_key' : ['timestamp']\n",
    "        , 'timestamp_format' : [None]\n",
    "        , 'other_columns_keys' : [[]]\n",
    "\n",
    "        # Step 2 - Setting Window Strategy\n",
    "        , 'window_size_mode' : ['Fixed']\n",
    "        , 'window_size' : [8000]\n",
    "        , 'window_ref_mode' : ['Fixed'] #, 'Sliding'\n",
    "        , 'overlap' : [True]\n",
    "        , 'sliding_step' : [2000]\n",
    "\n",
    "        # Step 3 - Setting Process Representation (using Transition Matrix)\n",
    "        , 'threshold_anomaly': [0.005]\n",
    "        , 'control_flow_features': [{'frequency', 'probability', 'causality', 'parallel', 'choice', 'loop'}]\n",
    "        , 'time_features': [{}] \n",
    "        , 'resource_features': [{}]\n",
    "        , 'data_features': [{}]\n",
    "\n",
    "        # Step 4 - Setting Change Representation\n",
    "        , 'change_features_strategy_dict' : [{\n",
    "            'delta_matrix_strategy': \n",
    "                {\n",
    "                    'frequency_delta' : {'process_feature':'frequency', 'method':'aggregation', 'agg_function' : 'sum'}\n",
    "                    , 'frequency_delta_percentage' : {'process_feature':'frequency', 'method':'percentage'}\n",
    "                    # , 'prob_freq_delta_weight' : {'process_feature':'probability', 'method':'aggregation_weight', 'agg_function' : 'sum', 'weight_feature' : 'frequency'}\n",
    "                }\n",
    "            ,'statistic_test_strategy' : \n",
    "                {\n",
    "                    # 'frequency_gtest_pvalue' : {'process_feature':'frequency', 'method':'g_test', 'contingency_matrix_sum_value' : '5', 'remove_zeros':'True'}\n",
    "                    # , 'frequency_cramersv' : {'process_feature':'frequency', 'method':'cramers_v', 'contingency_matrix_sum_value' : '5', 'remove_zeros':'True'}\n",
    "                }\n",
    "        }]\n",
    "        \n",
    "        # Step 5 - Setting Detection Task\n",
    "        , 'detection_task_strategy_dict' :  [{\n",
    "            'time_series_strategy': \n",
    "                {\n",
    "                    # 'cpd_frequency_delta3' : {'change_features':['frequency_delta'], 'method':'cpd_pelt', 'smooth' : '3'}\n",
    "                    # 'cpd_prob_freq_delta3' : {'change_features':['prob_freq_delta_weight'], 'method':'cpd_pelt', 'smooth' : '3'}\n",
    "            #         , 'cpd_cramersv_frequency3' : {'change_features':['frequency_cramersv'], 'method':'cpd_pelt', 'smooth' : '3'} \n",
    "                }\n",
    "            ,'threshold_strategy' : \n",
    "                {\n",
    "                    # 'gtest_frequency3' : {'change_features':['frequency_gtest_pvalue'], 'method':'comparison_operator', 'operator' : 'le', 'threshold_value' : '0.025', 'smooth' : '3'}\n",
    "                    'fixed_frequency_delta_percentage3' : {'change_features':['frequency_delta_percentage'], 'method':'comparison_operator', 'operator' : 'ge', 'threshold_value' : '0.05', 'smooth' : '3'}\n",
    "                    # , 'fixed_cramersv_frequency3' : {'change_features':['frequency_cramersv'], 'method':'comparison_operator', 'operator' : 'ge', 'threshold_value' : '0.05', 'smooth' : '3'}\n",
    "                }\n",
    "        }]\n",
    "\n",
    "        # Step 6a - Localization Task\n",
    "        , 'reference_window_index': [0]\n",
    "        , 'detection_window_index': [14]\n",
    "        , 'pvalue_threshold': [0.05]\n",
    "        , 'effect_threshold': [0.2]\n",
    "        , 'presence_percentage_threshold': [0.01]\n",
    "        , 'pseudo_count': [5]\n",
    "\n",
    "        # Step 6b - Characterization Task\n",
    "        , 'llm_company' : ['google'] # 'google', 'openai'\n",
    "        , 'llm_model': [\"gemini-2.5-pro\"] # \"gemini-2.5-flash\", \"gemini-2.5-pro\", \"gpt-4o\", \"gpt-4.1\", \"o4-mini\", \"gpt-5\"\n",
    "        , 'api_key_path' : ['../Temp/google_api_key.txt'] # '../Temp/google_api_key.txt', '../Temp/openai_api_key.txt'\n",
    "        , 'llm_instructions_path': ['../Codes/LLM_Instructions/instructions_general_approach.yaml']\n",
    "\n",
    "    }]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine parameters GridSearch with all event logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TMPD_ParameterGrid_logs_experiment = []\n",
    "id=0\n",
    "for param_grid in TMPD_ParameterGrid_experiment:\n",
    "    for log_path in logs_path:\n",
    "        param_grid_aux = param_grid.copy()\n",
    "        param_grid_aux['log_path'] = log_path \n",
    "        param_grid_aux['id'] = id\n",
    "        TMPD_ParameterGrid_logs_experiment.append(param_grid_aux)\n",
    "        id = id+1\n",
    "len(TMPD_ParameterGrid_logs_experiment)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute all experiments in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050da02e0ec44139afe94696d3303552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\ConditionalMove\\output\\ConditionalMove.mxml.gz\n",
      "step 1\n",
      "step 2\n",
      "step 3\n",
      "step 4\n",
      "step 6a\n",
      "step 6b\n",
      "Validation metrics\n",
      "Adding informations\n",
      "../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\ConditionalRemoval\\output\\ConditionalRemoval.mxml.gz\n",
      "step 1\n",
      "step 2\n",
      "step 3\n",
      "step 4\n",
      "step 6a\n",
      "step 6b\n",
      "Validation metrics\n",
      "Adding informations\n",
      "../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\ConditionalToSequence\\output\\ConditionalToSequence.mxml.gz\n",
      "step 1\n",
      "step 2\n",
      "step 3\n",
      "step 4\n",
      "step 6a\n",
      "step 6b\n",
      "Validation metrics\n",
      "Adding informations\n",
      "../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\Frequency\\output\\Frequency.mxml.gz\n",
      "step 1\n",
      "step 2\n",
      "step 3\n",
      "step 4\n",
      "step 6a\n",
      "step 6b\n",
      "Validation metrics\n",
      "Adding informations\n",
      "../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\Loop\\output\\Loop.mxml.gz\n",
      "step 1\n",
      "step 2\n",
      "step 3\n",
      "step 4\n",
      "step 6a\n",
      "step 6b\n",
      "Validation metrics\n",
      "Adding informations\n",
      "../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\ParallelMove\\output\\ParallelMove.mxml.gz\n",
      "step 1\n",
      "step 2\n",
      "step 3\n",
      "step 4\n",
      "step 6a\n",
      "step 6b\n",
      "Validation metrics\n",
      "Adding informations\n",
      "../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\ParallelRemoval\\output\\ParallelRemoval.mxml.gz\n",
      "step 1\n",
      "step 2\n",
      "step 3\n",
      "step 4\n",
      "step 6a\n",
      "step 6b\n",
      "Validation metrics\n",
      "Adding informations\n",
      "../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\ParallelToSequence\\output\\ParallelToSequence.mxml.gz\n",
      "step 1\n",
      "step 2\n",
      "step 3\n",
      "step 4\n",
      "step 6a\n",
      "step 6b\n",
      "Validation metrics\n",
      "Adding informations\n",
      "../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\SerialMove\\output\\SerialMove.mxml.gz\n",
      "step 1\n",
      "step 2\n",
      "step 3\n",
      "step 4\n",
      "step 6a\n",
      "step 6b\n",
      "Validation metrics\n",
      "Adding informations\n",
      "../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\SerialRemoval\\output\\SerialRemoval.mxml.gz\n",
      "step 1\n",
      "step 2\n",
      "step 3\n",
      "step 4\n",
      "step 6a\n",
      "step 6b\n",
      "Validation metrics\n",
      "Adding informations\n",
      "../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\Skip\\output\\Skip.mxml.gz\n",
      "step 1\n",
      "step 2\n",
      "step 3\n",
      "step 4\n",
      "step 6a\n",
      "step 6b\n",
      "Validation metrics\n",
      "Adding informations\n",
      "../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\Substitute\\output\\Substitute.mxml.gz\n",
      "step 1\n",
      "step 2\n",
      "step 3\n",
      "step 4\n",
      "step 6a\n",
      "step 6b\n",
      "Validation metrics\n",
      "Adding informations\n",
      "../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange\\Size1\\Atomic\\Swap\\output\\Swap.mxml.gz\n",
      "step 1\n",
      "step 2\n",
      "step 3\n",
      "step 4\n",
      "step 6a\n",
      "step 6b\n",
      "Validation metrics\n",
      "Adding informations\n"
     ]
    }
   ],
   "source": [
    "TMPD_logs_results_experiment = Parallel(n_jobs=1)(delayed(run_pipeline_TMPD)(TMPD_Parameters, display=False, return_bool=True) for TMPD_Parameters in tqdm_notebook(TMPD_ParameterGrid_logs_experiment))\n",
    "TMPD_logs_results_experiment_df = pd.concat(TMPD_logs_results_experiment, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMPD_logs_results_experiment_df.to_excel('Results/CPN_Logs_Characterization_Ext_Ostovar_Robust_Understanding_Task_general_approach_gemini25pro.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4479e0a5046c62b3193360939b9555042324f3c1ca8424e4ac0e4f7948559ebe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
