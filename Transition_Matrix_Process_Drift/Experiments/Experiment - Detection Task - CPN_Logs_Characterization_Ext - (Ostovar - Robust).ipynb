{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: Detection Task on CPN_Logs_Characterization_Ext - (Ostovar - Robust)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lib Imports and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "# %matplotlib inline \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import io\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pm4py\n",
    "import ruptures as rpt\n",
    "from ruptures.metrics import precision_recall, meantime\n",
    "import scipy.stats as ss\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import time\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "sys.path.append(\"../Codes/\")\n",
    "import TMPD_utils\n",
    "import TMPD_class\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_colwidth', 150)\n",
    "# pd.set_option('display.float_format', lambda x: f'{x:,.3f}')\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "np.set_printoptions(threshold=sys.maxsize)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to run the class TMPD pipeline in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline_TMPD(kwargs, display=False, return_bool=False):\n",
    "    \n",
    "    try:\n",
    "\n",
    "        ### Loading event log\n",
    "        # Extracting event log\n",
    "        event_log = TMPD_utils.parse_mxml(kwargs['log_path'], gzip=True)\n",
    "\n",
    "        # This is a specifc step for this event log that remove an activity that shows where the drift happens\n",
    "        event_log = event_log[event_log['WorkflowModelElement'] != 'DRIFT_PO']\n",
    "\n",
    "        # Save original event index\n",
    "        event_log = event_log.reset_index(names='original_index') \n",
    "\n",
    "        # Create an id based on the order of the event in the raw event log\n",
    "        event_log[\"Event_order_id\"] = event_log.index\n",
    "\n",
    "        ### Step 1 - Instantiating class and setting event log\n",
    "        print('step 1')\n",
    "        # Iniatializing the TMPD_class\n",
    "        TMPD_instance = TMPD_class.TMPD(scenario='offline')\n",
    "\n",
    "        # Setting the transition log\n",
    "        TMPD_instance.set_transition_log(event_log, case_id = kwargs['case_id'], activity_key = kwargs['activity_key']\n",
    "                                         , timestamp_key = kwargs['timestamp_key'], timestamp_format=kwargs['timestamp_format'], other_columns_keys=kwargs['other_columns_keys'])\n",
    "\n",
    "        # Executing the transition log\n",
    "        TMPD_instance.run_transition_log()\n",
    "\n",
    "        # Showing the transition log created\n",
    "        # TMPD_instance.get_transition_log().head(15)\n",
    "\n",
    "        \n",
    "        ### Step 2 - Setting Window Strategy\n",
    "        print('step 2')\n",
    "        # Setting the window strategy parameters\n",
    "        TMPD_instance.set_windowing_strategy(window_size_mode = kwargs['window_size_mode'], window_size = kwargs['window_size'], window_ref_mode = kwargs['window_ref_mode']\n",
    "                                                , overlap = kwargs['overlap'], sliding_step = kwargs['sliding_step'])\n",
    "\n",
    "        # Executing the window strategy indexation\n",
    "        TMPD_instance.run_windowing_strategy()\n",
    "\n",
    "        # Showing the windows indexes\n",
    "        # dict(list(TMPD_instance.get_windowing_strategy().items())[:15])\n",
    "\n",
    "\n",
    "        ### Step 3 - Setting Process Representation (using Transition Matrix)\n",
    "        print('step 3')\n",
    "        # Setting the Transition Matrix (TM) process representation\n",
    "        TMPD_instance.set_process_representation(threshold_anomaly = kwargs['threshold_anomaly']\n",
    "                                            , control_flow_features = kwargs['control_flow_features']\n",
    "                                            , time_features = kwargs['time_features']\n",
    "                                            , resource_features = kwargs['resource_features']\n",
    "                                            , data_features = kwargs['data_features'])\n",
    "\n",
    "        # Executing the process_representation using all dataset just for an example\n",
    "        # TMPD_instance.run_process_representation(TMPD_instance.transition_log)\n",
    "\n",
    "        # Showing the process representation created\n",
    "        # TMPD_instance.get_process_representation().head(15)\n",
    "\n",
    "\n",
    "        ### Step 4 - Setting Change Representation\n",
    "        print('step 4')\n",
    "        # Setting Change Representation\n",
    "        TMPD_instance.set_change_representation(kwargs['change_features_strategy_dict'])\n",
    "\n",
    "        # Executing the Change Representation using the window strategy\n",
    "        TMPD_instance.run_change_representation()\n",
    "\n",
    "        # Showing the Change Representation created\n",
    "        # TMPD_instance.get_change_representation().head(15)\n",
    "\n",
    "\n",
    "        ### Step 5 - Setting Detection Task\n",
    "        print('step 5')\n",
    "        # Setting Detection Task\n",
    "        TMPD_instance.set_detection_task(kwargs['detection_task_strategy_dict'])\n",
    "\n",
    "        # Executing the Detection Task\n",
    "        TMPD_instance.run_detection_task()\n",
    "\n",
    "        # Getting Detection Task Results\n",
    "        detection_task_results = TMPD_instance.get_detection_task()\n",
    "\n",
    "\n",
    "        ### Defining Grounding truth\n",
    "        print('Grounding truth')\n",
    "        ground_truth_traces_indexes = [\"1000\", \"2000\"]\n",
    "\n",
    "        transition_log = TMPD_instance.get_transition_log()\n",
    "        ground_truth_events_indexes = transition_log[transition_log['case_id'].isin(ground_truth_traces_indexes)].groupby('case_id').first()['transition_id'].to_list()\n",
    "\n",
    "        # signals_indexes = signals.reset_index()\n",
    "        signals = TMPD_instance.get_change_representation()\n",
    "        ground_truth = []\n",
    "        for ground_truth_events_index in ground_truth_events_indexes:\n",
    "            ground_truth.extend(signals[(signals['start'] <= ground_truth_events_index) \n",
    "                        & (signals['end'] >= ground_truth_events_index)].head(1).index.to_list())\n",
    "        ground_truth = ground_truth + [len(signals)]\n",
    "        # print(\"ground_truth: \", ground_truth)\n",
    "\n",
    "        ### Validation metrics\n",
    "        print('Validation metrics')\n",
    "        for index, row in detection_task_results.iterrows():\n",
    "            try:\n",
    "                detection_task_results.loc[index, 'ground_truth'] = str(ground_truth)\n",
    "\n",
    "                # smooth = int(kwargs['detection_task_strategy_dict'][row['detection_strategy']][row['detection_feature']]['smooth'])\n",
    "\n",
    "                # Margin of error give more margin to overlap if used.\n",
    "                margin_error = int(kwargs['margin_error'] + 1)  if kwargs['overlap'] == False else int(kwargs['margin_error'] + 1 + kwargs['window_size']/kwargs['sliding_step'])\n",
    "\n",
    "                precision, recall = precision_recall(ground_truth, row['detection_results'], margin=margin_error)\n",
    "\n",
    "                f1 = round(ss.hmean([precision, recall]),2)\n",
    "                detection_task_results.loc[index, 'f1'] = f1\n",
    "                \n",
    "                delay = round(meantime(ground_truth, row['detection_results']), 2)\n",
    "                detection_task_results.loc[index, 'delay'] = delay\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(\"Error:\", e)\n",
    "                detection_task_results.loc[index, 'ground_truth'] = str(ground_truth)\n",
    "                detection_task_results.loc[index, 'f1'] = np.nan\n",
    "                detection_task_results.loc[index, 'delay'] = np.nan\n",
    "\n",
    "\n",
    "        ### Add informations to final result\n",
    "        print('Adding informations')\n",
    "        detection_task_results['log_path'] = kwargs['log_path']\n",
    "        detection_task_results['log_size'] = kwargs['log_path'].split(\"\\\\\")[-5] \n",
    "        detection_task_results['mix_type'] = kwargs['log_path'].split(\"\\\\\")[-4]\n",
    "        detection_task_results['change_pattern'] = kwargs['log_path'].split(\"\\\\\")[-3]\n",
    "        detection_task_results['noise_size'] = kwargs['log_path'].split(\"\\\\\")[-1].split(\".\")[0].split(\"_\")[-1] if kwargs['log_path'].split(\"\\\\\")[-1].split(\".\")[0].split(\"_\")[-1].isdigit() else 0\n",
    "        detection_task_results['window_size_mode'] = kwargs['window_size_mode']\n",
    "        detection_task_results['window_size'] = kwargs['window_size']\n",
    "        detection_task_results['window_ref_mode'] = kwargs['window_ref_mode']\n",
    "        detection_task_results['overlap'] = kwargs['overlap']\n",
    "        detection_task_results['sliding_step'] = kwargs['sliding_step']\n",
    "        detection_task_results['margin_error'] = kwargs['margin_error']\n",
    "        detection_task_results['margin_error_corrected'] = margin_error\n",
    "\n",
    "\n",
    "        ### Display results\n",
    "        if display:\n",
    "            print('Display results')\n",
    "            display_list = []\n",
    "            for index, result in detection_task_results.iterrows():\n",
    "                print(ground_truth, result['detection_results'])\n",
    "                fig, axarr = rpt.display(signal=TMPD_instance.get_change_representation()[TMPD_instance.detection_task_strategy_dict[result['detection_strategy']][result['detection_feature']]['change_features']]\n",
    "                            , true_chg_pts=ground_truth\n",
    "                            , computed_chg_pts=result['detection_results']\n",
    "                            , computed_chg_pts_color=\"k\"\n",
    "                            , computed_chg_pts_linewidth=4\n",
    "                            , computed_chg_pts_linestyle=\"--\"\n",
    "                            , computed_chg_pts_alpha=1\n",
    "                            , figsize=(15, 3)\n",
    "                            )\n",
    "                plt.suptitle(\"Change Pat.: \" + str(detection_task_results.loc[index, 'change_pattern'])\n",
    "                            + \" - Mix type: \" + str(detection_task_results.loc[index, 'mix_type'])\n",
    "                            + \" - Size: \" + str(detection_task_results.loc[index, 'log_size'])\n",
    "                            + \" - Noise: \" + str(detection_task_results.loc[index, 'noise_size'])\n",
    "                            + \" - Feature: \" + str(detection_task_results.loc[index, 'detection_feature']) \n",
    "                            + \" - F1: \" + str(detection_task_results.loc[index, 'f1']) \n",
    "                            + \" - Delay: \" + str(detection_task_results.loc[index, 'delay']) \n",
    "                            , fontsize=15)\n",
    "                plt.subplots_adjust(top=0.8)\n",
    "                \n",
    "                with io.BytesIO() as buff:\n",
    "                    fig.savefig(buff, format='raw')\n",
    "                    buff.seek(0)\n",
    "                    data = np.frombuffer(buff.getvalue(), dtype=np.uint8)\n",
    "                w, h = fig.canvas.get_width_height()\n",
    "                im = data.reshape((int(h), int(w), -1))\n",
    "                display_list.append(im)\n",
    "\n",
    "            detection_task_results['display'] = display_list\n",
    "\n",
    "    except Exception as e:\n",
    "        detection_task_results = pd.DataFrame(data={'Error': [e]})\n",
    "        detection_task_results['log_path'] = kwargs['log_path']\n",
    "        detection_task_results['log_size'] = kwargs['log_path'].split(\"\\\\\")[-5] \n",
    "        detection_task_results['mix_type'] = kwargs['log_path'].split(\"\\\\\")[-4]\n",
    "        detection_task_results['change_pattern'] = kwargs['log_path'].split(\"\\\\\")[-3]\n",
    "        detection_task_results['noise_size'] = kwargs['log_path'].split(\"\\\\\")[-1].split(\".\")[0].split(\"_\")[-1] if kwargs['log_path'].split(\"\\\\\")[-1].split(\".\")[0].split(\"_\")[-1].isdigit() else 0\n",
    "        detection_task_results['window_size_mode'] = kwargs['window_size_mode']\n",
    "        detection_task_results['window_size'] = kwargs['window_size']\n",
    "        detection_task_results['window_ref_mode'] = kwargs['window_ref_mode']\n",
    "        detection_task_results['overlap'] = kwargs['overlap']\n",
    "        detection_task_results['sliding_step'] = kwargs['sliding_step']\n",
    "        detection_task_results['margin_error'] = kwargs['margin_error']\n",
    "    \n",
    "    # Deleting class instance\n",
    "    try:\n",
    "        del TMPD_instance\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Returning detection results or save to file\n",
    "    if return_bool:\n",
    "        return detection_task_results\n",
    "    else:\n",
    "        detection_task_results.to_pickle(\"Results/CPN_Logs_Characterization_Ext_Ostovar_Robust_files/\"+ str(kwargs['id']) + \".pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading CPN_Logs_Characterization_Ext - (Ostovar - Robust) event logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping all event_logs paths\n",
    "logs_path = glob.glob(\"../Input/Synthetic/CPN_Logs (Ostovar - Robust)/FragmentChange/*/*/*/*/*.mxml*\")\n",
    "\n",
    "# Showing mapped paths\n",
    "print(\"How many logs? \", len(logs_path))\n",
    "pd.DataFrame(logs_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![Alt text](../Images/Concept_drift_firstcycle_steps_eng.png \"General steps\") -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment impacts of the parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Parameters GridSearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Grid Search of parameters\n",
    "TMPD_ParameterGrid = ParameterGrid(\n",
    "    [{\n",
    "        # Step 1 - Instantiating class and setting event log\n",
    "        'case_id' : ['CaseId']\n",
    "        , 'activity_key' : ['Activity']\n",
    "        , 'timestamp_key' : ['timestamp']\n",
    "        , 'timestamp_format' : [None]\n",
    "        , 'other_columns_keys' : [[]]\n",
    "\n",
    "        # Step 2 - Setting Window Strategy\n",
    "        , 'window_size_mode' : ['Fixed']\n",
    "        , 'window_size' : [6000, 8000, 10000] #2000, 4000\n",
    "        , 'window_ref_mode' : ['Fixed'] #, 'Sliding'\n",
    "        , 'overlap' : [True]\n",
    "        , 'sliding_step' : [1000, 2000, 4000] # 200, 500\n",
    "\n",
    "        # Step 3 - Setting Process Representation (using Transition Matrix)\n",
    "        , 'threshold_anomaly': [0]\n",
    "        , 'control_flow_features': [{'frequency', 'probability'}]\n",
    "        , 'time_features': [{}] \n",
    "        , 'resource_features': [{}]\n",
    "        , 'data_features': [{}]\n",
    "\n",
    "        # Step 4 - Setting Change Representation\n",
    "        , 'change_features_strategy_dict' : [{\n",
    "            'delta_matrix_strategy': \n",
    "                {\n",
    "                    'frequency_delta' : {'process_feature':'frequency', 'method':'aggregation', 'agg_function' : 'sum'}\n",
    "                    , 'frequency_delta_percentage' : {'process_feature':'frequency', 'method':'percentage'}\n",
    "                    , 'prob_freq_delta_weight' : {'process_feature':'probability', 'method':'aggregation_weight', 'agg_function' : 'sum', 'weight_feature' : 'frequency'}\n",
    "                }\n",
    "            , 'statistic_test_strategy' : \n",
    "                {\n",
    "                    'frequency_gtest_pvalue' : {'process_feature':'frequency', 'method':'g_test', 'contingency_matrix_sum_value' : '5', 'remove_zeros':'True'}\n",
    "                    , 'frequency_cramersv' : {'process_feature':'frequency', 'method':'cramers_v', 'contingency_matrix_sum_value' : '5', 'remove_zeros':'True'}\n",
    "                }\n",
    "        }]\n",
    "        \n",
    "        # Step 5 - Setting Detection Task\n",
    "        , 'detection_task_strategy_dict' :  [\n",
    "            {\n",
    "            'time_series_strategy': \n",
    "                {\n",
    "                    'cpd_frequency_delta3' : {'change_features':['frequency_delta'], 'method':'cpd_pelt', 'smooth' : '3'}\n",
    "                    , 'cpd_prob_freq_delta3' : {'change_features':['prob_freq_delta_weight'], 'method':'cpd_pelt', 'smooth' : '3'}\n",
    "                    , 'cpd_cramersv_frequency3' : {'change_features':['frequency_cramersv'], 'method':'cpd_pelt', 'smooth' : '3'} \n",
    "                }\n",
    "            , 'threshold_strategy' : \n",
    "                {\n",
    "                    'gtest_frequency3' : {'change_features':['frequency_gtest_pvalue'], 'method':'comparison_operator', 'operator' : 'le', 'threshold_value' : '0.025', 'smooth' : '3'}\n",
    "                    , 'fixed_frequency_delta_percentage3' : {'change_features':['frequency_delta_percentage'], 'method':'comparison_operator', 'operator' : 'ge', 'threshold_value' : '0.05', 'smooth' : '3'}\n",
    "                    , 'fixed_cramersv_frequency3' : {'change_features':['frequency_cramersv'], 'method':'comparison_operator', 'operator' : 'ge', 'threshold_value' : '0.05', 'smooth' : '3'}\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        , 'margin_error' : [3]\n",
    "    }\n",
    "    , {\n",
    "        # Step 1 - Instantiating class and setting event log\n",
    "        'case_id' : ['CaseId']\n",
    "        , 'activity_key' : ['Activity']\n",
    "        , 'timestamp_key' : ['timestamp']\n",
    "        , 'timestamp_format' : [None]\n",
    "        , 'other_columns_keys' : [[]]\n",
    "\n",
    "        # Step 2 - Setting Window Strategy\n",
    "        , 'window_size_mode' : ['Fixed']\n",
    "        , 'window_size' : [6000, 8000] #2000, 4000\n",
    "        , 'window_ref_mode' : ['Fixed'] #, 'Sliding'\n",
    "        , 'overlap' : [False]\n",
    "        , 'sliding_step' : [0]\n",
    "\n",
    "        # Step 3 - Setting Process Representation (using Transition Matrix)\n",
    "        , 'threshold_anomaly': [0]\n",
    "        , 'control_flow_features': [{'frequency', 'probability'}]\n",
    "        , 'time_features': [{}] \n",
    "        , 'resource_features': [{}]\n",
    "        , 'data_features': [{}]\n",
    "\n",
    "        # Step 4 - Setting Change Representation\n",
    "        , 'change_features_strategy_dict' : [{\n",
    "            'delta_matrix_strategy': \n",
    "                {\n",
    "                    'frequency_delta' : {'process_feature':'frequency', 'method':'aggregation', 'agg_function' : 'sum'}\n",
    "                    , 'frequency_delta_percentage' : {'process_feature':'frequency', 'method':'percentage'}\n",
    "                    , 'prob_freq_delta_weight' : {'process_feature':'probability', 'method':'aggregation_weight', 'agg_function' : 'sum', 'weight_feature' : 'frequency'}\n",
    "                }\n",
    "            , 'statistic_test_strategy' : \n",
    "                {\n",
    "                    'frequency_gtest_pvalue' : {'process_feature':'frequency', 'method':'g_test', 'contingency_matrix_sum_value' : '5', 'remove_zeros':'True'}\n",
    "                    , 'frequency_cramersv' : {'process_feature':'frequency', 'method':'cramers_v', 'contingency_matrix_sum_value' : '5', 'remove_zeros':'True'}\n",
    "                }\n",
    "        }]\n",
    "        \n",
    "        # Step 5 - Setting Detection Task\n",
    "        , 'detection_task_strategy_dict' :  [\n",
    "            {\n",
    "            'time_series_strategy': \n",
    "                {\n",
    "                    'cpd_frequency_delta3' : {'change_features':['frequency_delta'], 'method':'cpd_pelt', 'smooth' : '3'}\n",
    "                    , 'cpd_prob_freq_delta3' : {'change_features':['prob_freq_delta_weight'], 'method':'cpd_pelt', 'smooth' : '3'}\n",
    "                    , 'cpd_cramersv_frequency3' : {'change_features':['frequency_cramersv'], 'method':'cpd_pelt', 'smooth' : '3'}  \n",
    "                }\n",
    "            , 'threshold_strategy' : \n",
    "                {\n",
    "                    'gtest_frequency3' : {'change_features':['frequency_gtest_pvalue'], 'method':'comparison_operator', 'operator' : 'le', 'threshold_value' : '0.025', 'smooth' : '3'}\n",
    "                    , 'fixed_frequency_delta_percentage3' : {'change_features':['frequency_delta_percentage'], 'method':'comparison_operator', 'operator' : 'ge', 'threshold_value' : '0.05', 'smooth' : '3'}\n",
    "                    , 'fixed_cramersv_frequency3' : {'change_features':['frequency_cramersv'], 'method':'comparison_operator', 'operator' : 'ge', 'threshold_value' : '0.05', 'smooth' : '3'}\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        , 'margin_error' : [3]\n",
    "    }\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine parameters GridSearch with all event logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMPD_ParameterGrid_logs = []\n",
    "id=0\n",
    "for param_grid in TMPD_ParameterGrid:\n",
    "    for log_path in logs_path:\n",
    "        param_grid_aux = param_grid.copy()\n",
    "        param_grid_aux['log_path'] = log_path \n",
    "        param_grid_aux['id'] = id\n",
    "        TMPD_ParameterGrid_logs.append(param_grid_aux)\n",
    "        id = id+1\n",
    "len(TMPD_ParameterGrid_logs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute all experiments in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executing parameter grid in parallel\n",
    "Parallel(n_jobs=-1)(delayed(run_pipeline_TMPD)(TMPD_Parameters, display=False, return_bool=False) for TMPD_Parameters in tqdm_notebook(TMPD_ParameterGrid_logs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading all executes\n",
    "saved_pkls = glob.glob(\"Results/CPN_Logs_Characterization_Ext_Ostovar_Robust_files/*.pkl\")\n",
    "results = []\n",
    "for saved_pkl in saved_pkls:\n",
    "    results.append(pd.read_pickle(saved_pkl))\n",
    "results_df = pd.concat(results, axis=0, ignore_index=True)\n",
    "results_df.to_csv('Results/CPN_Logs_Characterization_Ext_Ostovar_Robust.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv('Results/CPN_Logs_Characterization_Ext_Ostovar_Robust.csv', index_col=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ['detection_strategy', 'detection_feature', 'window_size_mode', 'window_size', 'window_ref_mode', 'overlap', 'sliding_step', 'margin_error'] \n",
    "validation_metrics = [\"f1\",\"delay\"]\n",
    "\n",
    "results_df_agg = results_df.groupby(params)[validation_metrics].agg(['mean'])\n",
    "results_df_agg.columns = results_df_agg.columns.map('_'.join)\n",
    "# results_df_agg.sort_values([\"f1_mean\",\"delay_mean\"], ascending=[False,True], inplace=True)\n",
    "# # all_results_grouped.to_excel(OUTPUT_RESULTS + all_results_grouped_'+model+'.xlsx', sheet_name=model)\n",
    "results_df_agg.head(200)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run specific experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMPD_ParameterGrid_experiment = ParameterGrid(\n",
    "    [{\n",
    "        # Step 1 - Instantiating class and setting event log\n",
    "        'case_id' : ['CaseId']\n",
    "        , 'activity_key' : ['Activity']\n",
    "        , 'timestamp_key' : ['timestamp']\n",
    "        , 'timestamp_format' : [None]\n",
    "        , 'other_columns_keys' : [[]]\n",
    "\n",
    "        # Step 2 - Setting Window Strategy\n",
    "        , 'window_size_mode' : ['Fixed']\n",
    "        , 'window_size' : [8000]\n",
    "        , 'window_ref_mode' : ['Fixed'] #, 'Sliding'\n",
    "        , 'overlap' : [True]\n",
    "        , 'sliding_step' : [2000]\n",
    "\n",
    "        # Step 3 - Setting Process Representation (using Transition Matrix)\n",
    "        , 'threshold_anomaly': [0]\n",
    "        , 'control_flow_features': [{'frequency', 'probability'}]\n",
    "        , 'time_features': [{}] \n",
    "        , 'resource_features': [{}]\n",
    "        , 'data_features': [{}]\n",
    "\n",
    "        # Step 4 - Setting Change Representation\n",
    "        , 'change_features_strategy_dict' : [{\n",
    "            'delta_matrix_strategy': \n",
    "                {\n",
    "                    'frequency_delta' : {'process_feature':'frequency', 'method':'aggregation', 'agg_function' : 'sum'}\n",
    "                    , 'frequency_delta_percentage' : {'process_feature':'frequency', 'method':'percentage'}\n",
    "                    # , 'prob_freq_delta_weight' : {'process_feature':'probability', 'method':'aggregation_weight', 'agg_function' : 'sum', 'weight_feature' : 'frequency'}\n",
    "                }\n",
    "            ,'statistic_test_strategy' : \n",
    "                {\n",
    "                    # 'frequency_gtest_pvalue' : {'process_feature':'frequency', 'method':'g_test', 'contingency_matrix_sum_value' : '5', 'remove_zeros':'True'}\n",
    "                    # , 'frequency_cramersv' : {'process_feature':'frequency', 'method':'cramers_v', 'contingency_matrix_sum_value' : '5', 'remove_zeros':'True'}\n",
    "                }\n",
    "        }]\n",
    "        \n",
    "        # Step 5 - Setting Detection Task\n",
    "        , 'detection_task_strategy_dict' :  [{\n",
    "            'time_series_strategy': \n",
    "                {\n",
    "                    # 'cpd_frequency_delta3' : {'change_features':['frequency_delta'], 'method':'cpd_pelt', 'smooth' : '3'}\n",
    "                    # 'cpd_prob_freq_delta3' : {'change_features':['prob_freq_delta_weight'], 'method':'cpd_pelt', 'smooth' : '3'}\n",
    "            #         , 'cpd_cramersv_frequency3' : {'change_features':['frequency_cramersv'], 'method':'cpd_pelt', 'smooth' : '3'} \n",
    "                }\n",
    "            ,'threshold_strategy' : \n",
    "                {\n",
    "                    # 'gtest_frequency3' : {'change_features':['frequency_gtest_pvalue'], 'method':'comparison_operator', 'operator' : 'le', 'threshold_value' : '0.025', 'smooth' : '3'}\n",
    "                    'fixed_frequency_delta_percentage3' : {'change_features':['frequency_delta_percentage'], 'method':'comparison_operator', 'operator' : 'ge', 'threshold_value' : '0.05', 'smooth' : '3'}\n",
    "                    # , 'fixed_cramersv_frequency3' : {'change_features':['frequency_cramersv'], 'method':'comparison_operator', 'operator' : 'ge', 'threshold_value' : '0.05', 'smooth' : '3'}\n",
    "                }\n",
    "        }]\n",
    "        , 'margin_error' : [3]\n",
    "    }]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMPD_ParameterGrid_logs_experiment = []\n",
    "id=0\n",
    "for param_grid in TMPD_ParameterGrid_experiment:\n",
    "    for log_path in logs_path:\n",
    "        param_grid_aux = param_grid.copy()\n",
    "        param_grid_aux['log_path'] = log_path \n",
    "        param_grid_aux['id'] = id\n",
    "        TMPD_ParameterGrid_logs_experiment.append(param_grid_aux)\n",
    "        id = id+1\n",
    "len(TMPD_ParameterGrid_logs_experiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMPD_logs_results_experiment = Parallel(n_jobs=2)(delayed(run_pipeline_TMPD)(TMPD_Parameters, display=True, return_bool=True) for TMPD_Parameters in tqdm_notebook(TMPD_ParameterGrid_logs_experiment))\n",
    "TMPD_logs_results_experiment_df = pd.concat(TMPD_logs_results_experiment, axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMPD_logs_results_experiment_df['f1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TMPD_logs_results_experiment_df.drop('display', axis=1).to_csv('Results/single_experiment_CPN_Logs_Characterization_Ext_Ostovar_Robust.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with PdfPages('Results/fixed_frequency_delta_percentage3_experiment_CPN_Logs_Characterization_Ext_Ostovar_Robust.pdf') as pdf:\n",
    "    for index, result in TMPD_logs_results_experiment_df.iterrows(): \n",
    "        fig, ax = plt.subplots(figsize=(15,3))\n",
    "        plt.axis('off')\n",
    "        ax.imshow(result['display'])\n",
    "        pdf.savefig(bbox_inches='tight')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4479e0a5046c62b3193360939b9555042324f3c1ca8424e4ac0e4f7948559ebe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
